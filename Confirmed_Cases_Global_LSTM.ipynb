{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Covid-19 Cases Predictions using LSTM Recurrent model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing the required python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM,GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping \n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Converting the data in CSV format to Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "id": "OQIJx4_WElkG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "615732.5190839694 780.9389223013303 609865.6003651633 374207.11342579103 374207.11342579103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_10700\\326440591.py:31: FutureWarning: The 'mad' method is deprecated and will be removed in a future version. To compute the same result, you may do `(df - df.mean()).abs().mean()`.\n",
            "  MAD = cases_trend.mad()\n",
            "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_10700\\326440591.py:32: FutureWarning: The 'mad' method is deprecated and will be removed in a future version. To compute the same result, you may do `(df - df.mean()).abs().mean()`.\n",
            "  AAD = cases_trend.mad()\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'  , sep = ',')\n",
        "\n",
        "cols = df.T.iloc[4: , :  ].diff().fillna(0).T\n",
        "df = pd.concat([df.iloc[: , 0:4] , cols]  , axis = 1 ) \n",
        "df.drop('Province/State' , axis = 1 , inplace = True)\n",
        "cols = df.columns\n",
        "\n",
        "dd  = pd.DataFrame(columns= cols)\n",
        "\n",
        "def fun(frame):\n",
        "    \n",
        "    mean_lat = frame['Lat'].mean() \n",
        "    meanlong = frame['Long'].mean() \n",
        "    country = frame['Country/Region'].values[0]\n",
        "    # print(frame)\n",
        "    a = frame.agg('sum')\n",
        "    a.Lat = mean_lat \n",
        "    a.Long = meanlong \n",
        "    a['Country/Region'] = country\n",
        "    vals = a.values\n",
        "    dd.loc[len(dd.index)] = list(vals)  \n",
        "\n",
        "df.groupby(['Country/Region']).apply(lambda frame  : fun(frame) )\n",
        "\n",
        "cases_trend = dd.iloc[: , 3 : ].agg('sum')\n",
        "cases_trend.rolling(100).mean().dropna(inplace = True)\n",
        "cases_day_wise = cases_trend.values\n",
        "standardDeviation = cases_day_wise.std()\n",
        "variance = np.sqrt(standardDeviation)\n",
        "average = cases_day_wise.mean()\n",
        "MAD = cases_trend.mad()\n",
        "AAD = cases_trend.mad()\n",
        "print(average, variance, standardDeviation, MAD , AAD) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# It only gives how many data points may be present around specified values.\n",
        "fig, (ax1 , ax2) = plt.subplots(1 ,2 , sharey=False ,sharex= False)\n",
        "fig.tight_layout()\n",
        "ax1 = cases_trend.plot.kde(bw_method = 0.3 , ax = ax1)\n",
        "ax2 = cases_trend.plot.hist(alpha=0.5 , ax = ax2)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(-52.35, 1099.35, -204217.05000000002, 4288558.05)"
            ]
          },
          "execution_count": 314,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ax = plt.plot(cases_trend)\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_size = 0.85\n",
        "split_ndx = int(dd.shape[0]*split_size )\n",
        "\n",
        "dd = dd.drop(['Lat' , 'Long'] , axis = 1 ).set_index('Country/Region')\n",
        "train_df = dd.iloc[ : split_ndx , : ]\n",
        "test_df =  dd.iloc[split_ndx : , :  ]  \n",
        "cols = dd.columns\n",
        "\n",
        "d = {} \n",
        "\n",
        "for i in cols : \n",
        "    d[i] = tf.int16\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating data in TensorFlow Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "voRIHVxCvY4T",
        "outputId": "275029a9-3b34-48ee-ef4b-7f8748d02461"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Using custom data configuration CovidData\n"
          ]
        }
      ],
      "source": [
        "my_ds_train = tf.data.Dataset.from_tensor_slices(dict(train_df))\n",
        "my_ds_test = tf.data.Dataset.from_tensor_slices(dict(test_df))\n",
        "\n",
        "# Optionally define a custom `data_dir`.\n",
        "# If None, then the default data dir is used.\n",
        "\n",
        "\n",
        "\n",
        "# Define the builder.\n",
        "\n",
        "covid_cases_builder = tfds.dataset_builders.TfDataBuilder(\n",
        "    name=\"Covid cases\",\n",
        "    config=\"CovidData\",\n",
        "    version=\"1.0.0\",\n",
        "    split_datasets={\n",
        "        \"train\": my_ds_train,\n",
        "        \"test\": my_ds_test,\n",
        "    },\n",
        "    features=tfds.features.FeaturesDict(d),\n",
        "    description=\"Dataset with covid cases\",\n",
        "    release_notes={\n",
        "        \"1.0.0\": \"Initial release with cases till 22 November , 2022\",\n",
        "    }\n",
        ")\n",
        "\n",
        "# Make the builder store the data as a TFDS dataset.\n",
        "covid_cases_builder.download_and_prepare()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = dd.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "id": "JcMHN5zsE3oG"
      },
      "outputs": [],
      "source": [
        "df22 = df.T[4:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "id": "DT4d5yoxR7fu"
      },
      "outputs": [],
      "source": [
        "df22['Sum'] = df22.sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "50egwgJv6RWH",
        "outputId": "0c421047-f4a0-4f0f-fde2-d79212da3506"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Country/Region</th>\n",
              "      <th>Afghanistan</th>\n",
              "      <th>Albania</th>\n",
              "      <th>Algeria</th>\n",
              "      <th>Andorra</th>\n",
              "      <th>Angola</th>\n",
              "      <th>Antarctica</th>\n",
              "      <th>Antigua and Barbuda</th>\n",
              "      <th>Argentina</th>\n",
              "      <th>Armenia</th>\n",
              "      <th>Australia</th>\n",
              "      <th>...</th>\n",
              "      <th>Uzbekistan</th>\n",
              "      <th>Vanuatu</th>\n",
              "      <th>Venezuela</th>\n",
              "      <th>Vietnam</th>\n",
              "      <th>West Bank and Gaza</th>\n",
              "      <th>Winter Olympics 2022</th>\n",
              "      <th>Yemen</th>\n",
              "      <th>Zambia</th>\n",
              "      <th>Zimbabwe</th>\n",
              "      <th>Sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1/26/20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1/27/20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>809</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows  202 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Country/Region  Afghanistan  Albania  Algeria  Andorra  Angola  Antarctica  \\\n",
              "1/26/20                   0        0        0        0       0           0   \n",
              "1/27/20                   0        0        0        0       0           0   \n",
              "\n",
              "Country/Region  Antigua and Barbuda  Argentina  Armenia  Australia  ...  \\\n",
              "1/26/20                           0          0        0          4  ...   \n",
              "1/27/20                           0          0        0          1  ...   \n",
              "\n",
              "Country/Region  Uzbekistan  Vanuatu  Venezuela  Vietnam  West Bank and Gaza  \\\n",
              "1/26/20                  0        0          0        0                   0   \n",
              "1/27/20                  0        0          0        0                   0   \n",
              "\n",
              "Country/Region  Winter Olympics 2022  Yemen  Zambia  Zimbabwe  Sum  \n",
              "1/26/20                            0      0       0         0  683  \n",
              "1/27/20                            0      0       0         0  809  \n",
              "\n",
              "[2 rows x 202 columns]"
            ]
          },
          "execution_count": 320,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df22.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "id": "bHzKjSnmrI5A"
      },
      "outputs": [],
      "source": [
        "dates = df.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {
        "id": "am_wqq0brfu6"
      },
      "outputs": [],
      "source": [
        "dates_prediction = dates[-194:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmNehNG_-lRO"
      },
      "source": [
        "# Splitting of Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OiQyDvo-Yha",
        "outputId": "507a5884-688f-4e24-95e0-8743e923a5f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "835\n",
            "209\n"
          ]
        }
      ],
      "source": [
        "df = df22\n",
        "close_data = df['Sum'].values\n",
        "close_data = close_data.reshape((-1,1))\n",
        "\n",
        "split_percent = 0.80\n",
        "split = int(split_percent*len(close_data))\n",
        "\n",
        "close_train = close_data[:split]\n",
        "close_test = close_data[split:]\n",
        "\n",
        "# date_train = df['Date'][:split]\n",
        "# date_test = df['Date'][split:]\n",
        "\n",
        "print(len(close_train))\n",
        "print(len(close_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "id": "PvpEriCM-kFM"
      },
      "outputs": [],
      "source": [
        "look_back = 15\n",
        "\n",
        "train_generator = TimeseriesGenerator(close_train, close_train, length=look_back, batch_size=20)     \n",
        "test_generator = TimeseriesGenerator(close_test, close_test, length=look_back, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUO3yXuF-ze0",
        "outputId": "33c5bae4-e7bb-4926-857d-c556c770e291"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_10700\\3894425179.py:11: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, epochs=num_epochs, verbose=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "41/41 [==============================] - 5s 7ms/step - loss: 825998704640.0000\n",
            "Epoch 2/125\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 814877245440.0000\n",
            "Epoch 3/125\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 803687497728.0000\n",
            "Epoch 4/125\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 789899640832.0000\n",
            "Epoch 5/125\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 773476712448.0000\n",
            "Epoch 6/125\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 756745961472.0000\n",
            "Epoch 7/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 733396008960.0000\n",
            "Epoch 8/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 709457215488.0000\n",
            "Epoch 9/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 684220022784.0000\n",
            "Epoch 10/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 651361058816.0000\n",
            "Epoch 11/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 615953858560.0000\n",
            "Epoch 12/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 582447464448.0000\n",
            "Epoch 13/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 538709000192.0000\n",
            "Epoch 14/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 494340866048.0000\n",
            "Epoch 15/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 443823849472.0000\n",
            "Epoch 16/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 397515390976.0000\n",
            "Epoch 17/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 342257893376.0000\n",
            "Epoch 18/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 290319073280.0000\n",
            "Epoch 19/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 231540523008.0000\n",
            "Epoch 20/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 71932076032.0000\n",
            "Epoch 21/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34158579712.0000\n",
            "Epoch 22/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34446536704.0000\n",
            "Epoch 23/125\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 33728964608.0000\n",
            "Epoch 24/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 34268850176.0000\n",
            "Epoch 25/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34234554368.0000\n",
            "Epoch 26/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 34171871232.0000\n",
            "Epoch 27/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34145173504.0000\n",
            "Epoch 28/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33600104448.0000\n",
            "Epoch 29/125\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 34381053952.0000\n",
            "Epoch 30/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33881229312.0000\n",
            "Epoch 31/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33683697664.0000\n",
            "Epoch 32/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33923328000.0000\n",
            "Epoch 33/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 34141386752.0000\n",
            "Epoch 34/125\n",
            "41/41 [==============================] - 1s 9ms/step - loss: 33550995456.0000\n",
            "Epoch 35/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 34454093824.0000\n",
            "Epoch 36/125\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 33869160448.0000\n",
            "Epoch 37/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33703641088.0000\n",
            "Epoch 38/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33766109184.0000\n",
            "Epoch 39/125\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 33677455360.0000\n",
            "Epoch 40/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33934811136.0000\n",
            "Epoch 41/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33746276352.0000\n",
            "Epoch 42/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34161934336.0000\n",
            "Epoch 43/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33347551232.0000\n",
            "Epoch 44/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33944266752.0000\n",
            "Epoch 45/125\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 33727756288.0000\n",
            "Epoch 46/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34123343872.0000\n",
            "Epoch 47/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34379325440.0000\n",
            "Epoch 48/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34046375936.0000\n",
            "Epoch 49/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33910265856.0000\n",
            "Epoch 50/125\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 34149990400.0000\n",
            "Epoch 51/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33958305792.0000\n",
            "Epoch 52/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34004256768.0000\n",
            "Epoch 53/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33890852864.0000\n",
            "Epoch 54/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33651202048.0000\n",
            "Epoch 55/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33798576128.0000\n",
            "Epoch 56/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33610668032.0000\n",
            "Epoch 57/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33889060864.0000\n",
            "Epoch 58/125\n",
            "41/41 [==============================] - 1s 12ms/step - loss: 33653022720.0000\n",
            "Epoch 59/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34148120576.0000\n",
            "Epoch 60/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33897164800.0000\n",
            "Epoch 61/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33828030464.0000\n",
            "Epoch 62/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34429378560.0000\n",
            "Epoch 63/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33584451584.0000\n",
            "Epoch 64/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33409503232.0000\n",
            "Epoch 65/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33673807872.0000\n",
            "Epoch 66/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33589125120.0000\n",
            "Epoch 67/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33726267392.0000\n",
            "Epoch 68/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33688915968.0000\n",
            "Epoch 69/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33516244992.0000\n",
            "Epoch 70/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33528322048.0000\n",
            "Epoch 71/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33489963008.0000\n",
            "Epoch 72/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33727567872.0000\n",
            "Epoch 73/125\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 33750773760.0000\n",
            "Epoch 74/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33290477568.0000\n",
            "Epoch 75/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33459122176.0000\n",
            "Epoch 76/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33495199744.0000\n",
            "Epoch 77/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33306189824.0000\n",
            "Epoch 78/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33611145216.0000\n",
            "Epoch 79/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 34025172992.0000\n",
            "Epoch 80/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33526417408.0000\n",
            "Epoch 81/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33941291008.0000\n",
            "Epoch 82/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33368395776.0000\n",
            "Epoch 83/125\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 33516734464.0000\n",
            "Epoch 84/125\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 34126817280.0000\n",
            "Epoch 85/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33484812288.0000\n",
            "Epoch 86/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33706797056.0000\n",
            "Epoch 87/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33337993216.0000\n",
            "Epoch 88/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33351387136.0000\n",
            "Epoch 89/125\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 33637132288.0000\n",
            "Epoch 90/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33298003968.0000\n",
            "Epoch 91/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33573316608.0000\n",
            "Epoch 92/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33884094464.0000\n",
            "Epoch 93/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33691617280.0000\n",
            "Epoch 94/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33373052928.0000\n",
            "Epoch 95/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33309597696.0000\n",
            "Epoch 96/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33447778304.0000\n",
            "Epoch 97/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33308596224.0000\n",
            "Epoch 98/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 34043418624.0000\n",
            "Epoch 99/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33466687488.0000\n",
            "Epoch 100/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33588305920.0000\n",
            "Epoch 101/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33413543936.0000\n",
            "Epoch 102/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33233600512.0000\n",
            "Epoch 103/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33323872256.0000\n",
            "Epoch 104/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33508753408.0000\n",
            "Epoch 105/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33180669952.0000\n",
            "Epoch 106/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33520041984.0000\n",
            "Epoch 107/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33516312576.0000\n",
            "Epoch 108/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33302609920.0000\n",
            "Epoch 109/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33436413952.0000\n",
            "Epoch 110/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33036304384.0000\n",
            "Epoch 111/125\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 33526265856.0000\n",
            "Epoch 112/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33390522368.0000\n",
            "Epoch 113/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33863737344.0000\n",
            "Epoch 114/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33449412608.0000\n",
            "Epoch 115/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33411616768.0000\n",
            "Epoch 116/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33170886656.0000\n",
            "Epoch 117/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33674618880.0000\n",
            "Epoch 118/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33462560768.0000\n",
            "Epoch 119/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33096206336.0000\n",
            "Epoch 120/125\n",
            "41/41 [==============================] - 1s 12ms/step - loss: 33436313600.0000\n",
            "Epoch 121/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33377024000.0000\n",
            "Epoch 122/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33184854016.0000\n",
            "Epoch 123/125\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 33429860352.0000\n",
            "Epoch 124/125\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 33397784576.0000\n",
            "Epoch 125/125\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 33191075840.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1979c6cca30>"
            ]
          },
          "execution_count": 325,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(\n",
        "    LSTM(10,\n",
        "        activation='relu',\n",
        "        input_shape=(look_back,1))\n",
        ")\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "num_epochs = 125\n",
        "model.fit_generator(train_generator, epochs=num_epochs, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UVmZ0Ys-5bx",
        "outputId": "f04f8fbe-3181-4d84-c746-a29a3a932fd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_10700\\1585461578.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  prediction = model.predict_generator(test_generator)\n"
          ]
        }
      ],
      "source": [
        "prediction = model.predict_generator(test_generator)\n",
        "\n",
        "close_train = close_train.reshape((-1))\n",
        "close_test = close_test.reshape((-1))\n",
        "prediction = prediction.reshape((-1))\n",
        "#prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzaDyiBHqcN3"
      },
      "source": [
        "# Accuracy for LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eE5Y8A9pkj3",
        "outputId": "9dbcb63d-6c02-4dff-8cf1-eb2239c82446"
      },
      "outputs": [],
      "source": [
        "# correct = df['Sum'].values\n",
        "correct = close_test.reshape((-1,1))\n",
        "correct = correct[-194:]\n",
        "#len(correct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM7V9LyptuTD",
        "outputId": "abef54bf-b12a-422c-feb6-dbcb19560db1"
      },
      "outputs": [],
      "source": [
        "#len(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "id": "XmtPpLr4sNgo"
      },
      "outputs": [],
      "source": [
        "mse = ((correct - prediction)**2).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGAGYrd4sW4l"
      },
      "source": [
        "# Prediction of cases along with the dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGCZiSAbuIwZ",
        "outputId": "0448c07b-870e-409f-8d04-63b1974e549a"
      },
      "outputs": [],
      "source": [
        "#dates_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "id": "ZTRboR7YsWU7"
      },
      "outputs": [],
      "source": [
        "type(dates_prediction) \n",
        "cases_dates = pd.DataFrame(dates_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "-td5fUqusxog"
      },
      "outputs": [],
      "source": [
        "cases_dates['Cases'] = prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Country wise predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "eBVCiKjGxduE",
        "outputId": "e026998e-8614-4d98-9bab-371e97dc82d5"
      },
      "outputs": [],
      "source": [
        "#df22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zGfykIE4UPZo",
        "outputId": "e7ab2c8e-0e58-4b54-e1fb-1a8133a27e2e"
      },
      "outputs": [],
      "source": [
        "df22 = df22.apply(lambda x: pd.to_numeric(x, errors='coerce')).dropna()\n",
        "#df22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "id": "eFC8nIaEyU2X"
      },
      "outputs": [],
      "source": [
        "df_new = df22[['Sum']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "id": "WuuiJYeEWQo_"
      },
      "outputs": [],
      "source": [
        "def partition_dataset(sequence_length, data, index):\n",
        "    x, y = [], []\n",
        "    data_len = data.shape[0]\n",
        "    for i in range(sequence_length, data_len):\n",
        "        x.append(data[i-sequence_length:i,:]) #contains sequence_length values 0-sequence_length * columsn\n",
        "        y.append(data[i, index]) #contains the prediction values for validation,  for single-step prediction\n",
        "\n",
        "    # Convert the x and y to numpy arrays\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model training - LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "id": "sNvUlOiWVbkF"
      },
      "outputs": [],
      "source": [
        "def getNext(feature, model):\n",
        "    df22 = df_new\n",
        "    data = df22\n",
        "    data_filtered = df22\n",
        "    data_filtered_ext = data_filtered.copy()\n",
        "    data_filtered_ext['Prediction'] = data_filtered_ext[feature]\n",
        "\n",
        "    nrows = data_filtered.shape[0]\n",
        "\n",
        "    # Convert the data to numpy values\n",
        "    np_data_unscaled = np.array(data_filtered)\n",
        "    np_data = np.reshape(np_data_unscaled, (nrows, -1))\n",
        "#     print(np_data.shape)\n",
        "\n",
        "    # Transform the data by scaling each feature to a range between 0 and 1\n",
        "    scaler = MinMaxScaler()\n",
        "#     print(np_data_unscaled.shape)\n",
        "    np_data_scaled = scaler.fit_transform(np_data_unscaled)\n",
        "\n",
        "    # Creating a separate scaler that works on a single column for scaling predictions\n",
        "    scaler_pred = MinMaxScaler()\n",
        "    df_Close = pd.DataFrame(data_filtered_ext[feature])\n",
        "    np_Close_scaled = scaler_pred.fit_transform(df_Close)\n",
        "    # Set the sequence length - this is the timeframe used to make a single prediction\n",
        "#     -----------------------------------------------------------------------------------------------------------------------------\n",
        "    # sequencing\n",
        "    sequence_length = 3\n",
        "\n",
        "    # Prediction Index\n",
        "    index = data.columns.get_loc(feature)\n",
        "\n",
        "    # Split the training data into train and train data sets\n",
        "    # As a first step, we get the number of rows to train the model on 80% of the data \n",
        "    train_data_len = math.ceil(np_data_scaled.shape[0] * 0.8)\n",
        "\n",
        "    # Create the training and test data\n",
        "    train_data = np_data_scaled[0:train_data_len, :]\n",
        "    test_data = np_data_scaled[train_data_len - sequence_length:, :]\n",
        "\n",
        "\n",
        "\n",
        "    # Generate training data and test data\n",
        "    x_train, y_train = partition_dataset(sequence_length, train_data, index)\n",
        "    x_test, y_test = partition_dataset(sequence_length, test_data, index)\n",
        "\n",
        "    # Print the shapes: the result is: (rows, training_sequence, features) (prediction value, )\n",
        "#     print(x_train.shape, y_train.shape)\n",
        "#     print(x_test.shape, y_test.shape)\n",
        "\n",
        "#     print(x_train[1][sequence_length-1][index])\n",
        "#     print(y_train[0])\n",
        "#     -----------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#     model = Sequential()\n",
        "\n",
        "    # Model with n_neurons = inputshape Timestamps, each with x_train.shape[2] variables\n",
        "    n_neurons = x_train.shape[1] * x_train.shape[2]\n",
        "#     print(n_neurons, x_train.shape[1], x_train.shape[2])\n",
        "    model.add(LSTM(n_neurons, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2]))) \n",
        "    model.add(LSTM(n_neurons, return_sequences=False))\n",
        "    model.add(Dense(5))\n",
        "    model.add(Dense(1))\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    #model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
        "    # model.compile(\n",
        "    #     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    #     optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "    #     metrics=[\"accuracy\"]\n",
        "    # )\n",
        "#-----------------------------------------------------------------------------------------------------------------------------\n",
        "    epochs = 125\n",
        "    batch_size = 8\n",
        "    early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
        "    history = model.fit(x_train, y_train, \n",
        "                        batch_size=batch_size, \n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_train, y_train)\n",
        "                    )\n",
        "#-----------------------------------------------------------------------------------------------------------------------------\n",
        "#     print(model.summary)\n",
        "    df_temp = df22[-sequence_length:]\n",
        "    new_df = df_temp\n",
        "    new_df\n",
        "    # N = sequence_length\n",
        "\n",
        "    last_N_days = new_df[-sequence_length:].values\n",
        "    last_N_days_scaled = scaler.transform(last_N_days)\n",
        "    # # Create an empty list and Append past N days\n",
        "    X_test_new = []\n",
        "    X_test_new.append(last_N_days_scaled)\n",
        "    # Convert the X_test data set to a numpy array and reshape the data\n",
        "    pred_cases_scaled = model.predict(np.array(X_test_new))\n",
        "    pred_cases_unscaled = scaler_pred.inverse_transform(pred_cases_scaled.reshape(-1, 1))\n",
        "    cases_today = np.round(new_df[feature][-1:], 2)\n",
        "    predicted_cases = np.round(pred_cases_unscaled.ravel()[0], 2)\n",
        "    change_percent = np.round(100 - (cases_today * 100)/predicted_cases, 2)\n",
        "\n",
        "    plus = '+'; minus = ''\n",
        "    print(f'The predicted value for feature (', {feature}, \"):  \" ,{predicted_cases})\n",
        "    return predicted_cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {
        "id": "JoTpGqkZZ8Dq"
      },
      "outputs": [],
      "source": [
        "# for col in df22.columns:\n",
        "#   print(df22[col].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkF-axyp649F"
      },
      "source": [
        "# Prediction for next 7 days covid cases.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-B4b4x5XCWK",
        "outputId": "99b7e9f0-ef5f-4891-b420-a7103b4d38c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "105/105 [==============================] - 17s 41ms/step - loss: 0.0254 - val_loss: 0.0209\n",
            "Epoch 2/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0177 - val_loss: 0.0128\n",
            "Epoch 3/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0079 - val_loss: 0.0036\n",
            "Epoch 4/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 5/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 6/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0030 - val_loss: 0.0032\n",
            "Epoch 7/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 8/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 9/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 10/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 11/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 12/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 13/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 14/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 15/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 16/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 17/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 18/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 19/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 20/125\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 21/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 22/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 23/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 24/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 25/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 26/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 27/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 28/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 29/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 30/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 31/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 32/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 33/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 34/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 35/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 36/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 37/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 38/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0035\n",
            "Epoch 39/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 40/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 41/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 42/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 43/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 44/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 45/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 46/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 47/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0028 - val_loss: 0.0025\n",
            "Epoch 48/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0026 - val_loss: 0.0030\n",
            "Epoch 49/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 50/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "Epoch 51/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 52/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 53/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 54/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 55/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 56/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 57/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 58/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 59/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 60/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 61/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 62/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 63/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 64/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 65/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 66/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 67/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 68/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 69/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0022 - val_loss: 0.0023\n",
            "Epoch 70/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 71/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 72/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 73/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 74/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 75/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 76/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 77/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 78/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 79/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 80/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 81/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 82/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 83/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 84/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 85/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 86/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 87/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 88/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 89/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 90/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 91/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 92/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 93/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 94/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 95/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 96/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 97/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 98/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 99/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 100/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 101/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 102/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 103/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 104/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 105/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 106/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 107/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 108/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 109/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 110/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 111/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0017\n",
            "Epoch 112/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 113/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 114/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 115/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 116/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 117/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 118/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 119/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 120/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 121/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 122/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 123/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 124/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 125/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "The predicted value for feature ( {'Sum'} ):   {300941.34}\n",
            "Epoch 1/125\n",
            "105/105 [==============================] - 11s 25ms/step - loss: 0.0279 - val_loss: 0.0231\n",
            "Epoch 2/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0195 - val_loss: 0.0134\n",
            "Epoch 3/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0069 - val_loss: 0.0030\n",
            "Epoch 4/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 5/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 6/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 7/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 8/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 9/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 10/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 11/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 0.0034\n",
            "Epoch 12/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 13/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 14/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 15/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 16/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 17/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 18/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 19/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 20/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 21/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 22/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 23/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 24/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 25/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 26/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 27/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 28/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 29/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 30/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0029 - val_loss: 0.0031\n",
            "Epoch 31/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 32/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 33/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 34/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "Epoch 35/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 36/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 37/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 38/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 39/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 40/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 41/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 42/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0031\n",
            "Epoch 43/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 44/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 45/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 46/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 47/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 48/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 49/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 50/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 51/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 52/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 53/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 54/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 55/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 56/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 57/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 58/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 59/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 60/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 61/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 62/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 63/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 64/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 65/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 66/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 67/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0024\n",
            "Epoch 68/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 69/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 70/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 71/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 72/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0026\n",
            "Epoch 73/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 74/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 75/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 76/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 77/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 78/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 79/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 80/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 81/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 82/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 83/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 84/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 85/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 86/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 87/125\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 88/125\n",
            "105/105 [==============================] - 2s 22ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 89/125\n",
            "105/105 [==============================] - 2s 21ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 90/125\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 91/125\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 92/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 93/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 94/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 95/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 96/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 97/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 98/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 99/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 100/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 101/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 102/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 103/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 104/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0019 - val_loss: 0.0017\n",
            "Epoch 105/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 106/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 107/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 108/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 109/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 110/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 111/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 112/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 113/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 114/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 115/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 116/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 117/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 118/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 119/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 120/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 121/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 122/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 123/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 124/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 125/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "The predicted value for feature ( {'Sum'} ):   {288403.6}\n",
            "Epoch 1/125\n",
            "105/105 [==============================] - 12s 30ms/step - loss: 0.0214 - val_loss: 0.0165\n",
            "Epoch 2/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0119 - val_loss: 0.0079\n",
            "Epoch 3/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0044 - val_loss: 0.0030\n",
            "Epoch 4/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 5/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 6/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 7/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0029 - val_loss: 0.0031\n",
            "Epoch 8/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 9/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 10/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 11/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 12/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 13/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 14/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 15/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 16/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0030 - val_loss: 0.0031\n",
            "Epoch 17/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 18/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 19/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 20/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 21/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 22/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 23/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 24/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 25/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 26/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 27/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 28/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 29/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 30/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 31/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 32/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 33/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0027 - val_loss: 0.0030\n",
            "Epoch 34/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 35/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 36/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0028 - val_loss: 0.0026\n",
            "Epoch 37/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0028 - val_loss: 0.0026\n",
            "Epoch 38/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 39/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 40/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 41/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 42/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0028 - val_loss: 0.0026\n",
            "Epoch 43/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 44/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 45/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 46/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 47/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 48/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 49/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 50/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 51/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 52/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 53/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 54/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 55/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 56/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 57/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 58/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 59/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 60/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 61/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "Epoch 62/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 63/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 64/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 65/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 66/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 67/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 68/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0022 - val_loss: 0.0023\n",
            "Epoch 69/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 70/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 71/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0022 - val_loss: 0.0023\n",
            "Epoch 72/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 73/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 74/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 75/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 76/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 77/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 78/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 79/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 80/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 81/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 82/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 83/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 84/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 85/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 86/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 87/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 88/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 89/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 90/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 91/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 92/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 93/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 94/125\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 95/125\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 96/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 97/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 98/125\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 99/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 100/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 101/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 102/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 103/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 104/125\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 105/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 106/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 107/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 108/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 109/125\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 110/125\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 111/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 112/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 113/125\n",
            "105/105 [==============================] - 2s 19ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 114/125\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 115/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 116/125\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 117/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 118/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 119/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 120/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 121/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 122/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 123/125\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 124/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 125/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "The predicted value for feature ( {'Sum'} ):   {316967.0}\n",
            "Epoch 1/125\n",
            "105/105 [==============================] - 13s 35ms/step - loss: 0.0285 - val_loss: 0.0238\n",
            "Epoch 2/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0213 - val_loss: 0.0165\n",
            "Epoch 3/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0099 - val_loss: 0.0040\n",
            "Epoch 4/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0032 - val_loss: 0.0033\n",
            "Epoch 5/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0033 - val_loss: 0.0032\n",
            "Epoch 6/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 7/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0032 - val_loss: 0.0030\n",
            "Epoch 8/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 9/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 10/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 11/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 12/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 13/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 14/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 15/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0030 - val_loss: 0.0031\n",
            "Epoch 16/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 17/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 18/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 19/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0030 - val_loss: 0.0032\n",
            "Epoch 20/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 21/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 22/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 23/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 24/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 25/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 26/125\n",
            "105/105 [==============================] - 2s 20ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 27/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 28/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 29/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 30/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 31/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 32/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 33/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 34/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 35/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 36/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 37/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 38/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 39/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 40/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "Epoch 41/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 42/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 43/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 44/125\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 45/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 46/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0028 - val_loss: 0.0026\n",
            "Epoch 47/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 48/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "Epoch 49/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 50/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 51/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 52/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 53/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 54/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 55/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 56/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 57/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 58/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 59/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "Epoch 60/125\n",
            "105/105 [==============================] - 2s 14ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 61/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 62/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 63/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0026 - val_loss: 0.0030\n",
            "Epoch 64/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 65/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 66/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 67/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 68/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 69/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 70/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 71/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 72/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 73/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 74/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 75/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 76/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 77/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "Epoch 78/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0024 - val_loss: 0.0022\n",
            "Epoch 79/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 80/125\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 81/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 82/125\n",
            "105/105 [==============================] - 2s 16ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 83/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 84/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 85/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 86/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 87/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 88/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 89/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 90/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 91/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 92/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 93/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 94/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 95/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 96/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 97/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 98/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 99/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 100/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 101/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 102/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 103/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 104/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 105/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 106/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 107/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 108/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 109/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 110/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 111/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 112/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 113/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 114/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 115/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 116/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 117/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 118/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 119/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 120/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 121/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 122/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 123/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 124/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 125/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "The predicted value for feature ( {'Sum'} ):   {318189.66}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_10700\\3707098864.py:96: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
            "  cases_today = np.round(new_df[feature][-1:], 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "105/105 [==============================] - 10s 21ms/step - loss: 0.0306 - val_loss: 0.0251\n",
            "Epoch 2/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0232 - val_loss: 0.0201\n",
            "Epoch 3/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0149 - val_loss: 0.0090\n",
            "Epoch 4/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0032\n",
            "Epoch 5/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 6/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 7/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 8/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0032\n",
            "Epoch 9/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 10/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 11/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 12/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0031\n",
            "Epoch 13/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 14/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 15/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0034\n",
            "Epoch 16/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 17/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0031\n",
            "Epoch 18/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 19/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 20/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 21/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 22/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 23/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 24/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 25/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0031\n",
            "Epoch 26/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 27/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 28/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 29/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 30/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 31/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 32/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 33/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 34/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 35/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 36/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 37/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 38/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 39/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 40/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 41/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 42/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 43/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 44/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 45/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 46/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 47/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 48/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0026\n",
            "Epoch 49/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 50/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 51/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 52/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 53/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 54/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 55/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 56/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 57/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 58/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 59/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 60/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 61/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 62/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 63/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 64/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 65/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 66/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 67/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 68/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 69/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 70/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 71/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 72/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 73/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 74/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 75/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 76/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 77/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 78/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 79/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 80/125\n",
            "105/105 [==============================] - 1s 14ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 81/125\n",
            "105/105 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 82/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 83/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 84/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 85/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 86/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 87/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 88/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 89/125\n",
            "105/105 [==============================] - 2s 17ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 90/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 91/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 92/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0017\n",
            "Epoch 93/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 94/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 95/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 96/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 97/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 98/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 99/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 100/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 101/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 102/125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 103/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 104/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 105/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 106/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 107/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 108/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 109/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 110/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 111/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 112/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 113/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 114/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 115/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 116/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 117/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 118/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 119/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 120/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 121/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 122/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 123/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 124/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 125/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "The predicted value for feature ( {'Sum'} ):   {335601.12}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_10700\\3707098864.py:96: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
            "  cases_today = np.round(new_df[feature][-1:], 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "105/105 [==============================] - 8s 24ms/step - loss: 0.0314 - val_loss: 0.0262\n",
            "Epoch 2/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0240 - val_loss: 0.0196\n",
            "Epoch 3/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0119 - val_loss: 0.0037\n",
            "Epoch 4/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0030\n",
            "Epoch 5/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 6/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0031\n",
            "Epoch 7/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 8/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 9/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 10/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 11/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 12/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 13/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 14/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 15/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 16/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 17/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 18/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 19/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 20/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 21/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 22/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 23/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 24/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 25/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 26/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "Epoch 27/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 28/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 29/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 30/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 31/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 32/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0029\n",
            "Epoch 33/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 34/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 35/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 36/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 37/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 38/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 39/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 40/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 41/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 42/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 43/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 44/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 45/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 46/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 47/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 48/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 49/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 50/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 51/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 52/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 53/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 54/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 55/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "Epoch 56/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 57/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 58/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 59/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 60/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 61/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 62/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 63/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 64/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 65/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 66/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 67/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 68/125\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 69/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 70/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 71/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 72/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 73/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 74/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 75/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 76/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 77/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 78/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 79/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 80/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 81/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 82/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 83/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 84/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 85/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 86/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 87/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 88/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 89/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 90/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 91/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 92/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 93/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 94/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 95/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 96/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 97/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 98/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 99/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 100/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 101/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 102/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 103/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 104/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 105/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 106/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 107/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 108/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 109/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 110/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 111/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 112/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 113/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 114/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 115/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 116/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 117/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 118/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 119/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 120/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 121/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 122/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 123/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 124/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 125/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "The predicted value for feature ( {'Sum'} ):   {319332.06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_10700\\3707098864.py:96: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
            "  cases_today = np.round(new_df[feature][-1:], 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "105/105 [==============================] - 12s 24ms/step - loss: 0.0267 - val_loss: 0.0217\n",
            "Epoch 2/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0108\n",
            "Epoch 3/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0031\n",
            "Epoch 4/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0032\n",
            "Epoch 5/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0032 - val_loss: 0.0032\n",
            "Epoch 6/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 7/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 8/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 9/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 10/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 11/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 12/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 13/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 14/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 15/125\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.0031 - val_loss: 0.0032\n",
            "Epoch 16/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 17/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 18/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0036\n",
            "Epoch 19/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0032 - val_loss: 0.0034\n",
            "Epoch 20/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 21/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 22/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0033\n",
            "Epoch 23/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 24/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 25/125\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 26/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 27/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 28/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 29/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 30/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 31/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 32/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 33/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 34/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 35/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 36/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 37/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 38/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 39/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 40/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0031\n",
            "Epoch 41/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 42/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 43/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 44/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 45/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 46/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 47/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 48/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 49/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 50/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 51/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 52/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 53/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 54/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 55/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 56/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 57/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 58/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 59/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 60/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 61/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 62/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 63/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 64/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 65/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 66/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 67/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 68/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "Epoch 69/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0026\n",
            "Epoch 70/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0028 - val_loss: 0.0030\n",
            "Epoch 71/125\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.0027 - val_loss: 0.0030\n",
            "Epoch 72/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 73/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 74/125\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "Epoch 75/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0025\n",
            "Epoch 76/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 77/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 78/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 79/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "Epoch 80/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 81/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 82/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 83/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "Epoch 84/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 85/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0026\n",
            "Epoch 86/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 87/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 88/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 89/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 90/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 91/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 92/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 93/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 94/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 95/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 96/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 97/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 98/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 99/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 100/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 101/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 102/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 103/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0022\n",
            "Epoch 104/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0024 - val_loss: 0.0022\n",
            "Epoch 105/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 106/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 107/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 108/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 109/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0023\n",
            "Epoch 110/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 111/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 112/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 113/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 114/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 115/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 116/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 117/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 118/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 119/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 120/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 121/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 122/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 123/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 124/125\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 125/125\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "The predicted value for feature ( {'Sum'} ):   {296732.12}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_10700\\3707098864.py:96: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
            "  cases_today = np.round(new_df[feature][-1:], 2)\n"
          ]
        }
      ],
      "source": [
        "next_7_days = []\n",
        "for i in range(7):\n",
        "  m = Sequential()\n",
        "  tmp = getNext('Sum', m)\n",
        "  df_new.loc[len(df_new)]= tmp\n",
        "  next_7_days.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAZzoMw-zrpN",
        "outputId": "f1837631-6a37-4ada-9f09-038b1dc4984f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average of next 7-Days Predicted Cases:  310880\n"
          ]
        }
      ],
      "source": [
        "A = [int(a) for a in next_7_days]\n",
        "print(\"Average of next 7-Days Predicted Cases: \",int(np.mean(A)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import date, timedelta\n",
        "\n",
        "dates = []\n",
        "for i in range(1,8):\n",
        "    days_after = (date.today()+timedelta(days=i)).isoformat()  \n",
        "    dates.append(days_after)\n",
        "\n",
        "#print(dates[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "id": "mUkrTqkM0oF7"
      },
      "outputs": [],
      "source": [
        "dict_dates_cases = {dates[0] : A[0], dates[1] : A[1], dates[2] : A[2], dates[3] : A[3], dates[4] : A[4], dates[5] : A[5], dates[6] : A[6]}\n",
        "#print(dict_dates_cases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTMPredictions_Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex_NjzRU08_1",
        "outputId": "79c8e38f-669c-4d82-8e24-6a07ec40ed67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted cases for the next 7 days:\n",
            "\n",
            "{'2022-12-06': 300941, '2022-12-07': 288403, '2022-12-08': 316967, '2022-12-09': 318189, '2022-12-10': 335601, '2022-12-11': 319332, '2022-12-12': 296732}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'2022-12-06': 300941,\n",
              " '2022-12-07': 288403,\n",
              " '2022-12-08': 316967,\n",
              " '2022-12-09': 318189,\n",
              " '2022-12-10': 335601,\n",
              " '2022-12-11': 319332,\n",
              " '2022-12-12': 296732}"
            ]
          },
          "execution_count": 343,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict_dates_cases\n",
        "print(\"Predicted cases for the next 7 days:\\n\")\n",
        "print(dict_dates_cases)\n",
        "\n",
        "names = list(dict_dates_cases.keys())\n",
        "values = list(dict_dates_cases.values())\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.bar(range(len(dict_dates_cases)), values, tick_label=names, color='salmon')\n",
        "plt.plot(names,values, color='blue')\n",
        "plt.title(\"Next 7Days Predicted Covid Cases using LSTM\")\n",
        "plt.show()\n",
        "dict_dates_cases\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
